{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLOOM Carbon Footprint : An Analysis of the logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook aims to analyse the SLURM logs of the experiments run on Jean Zay during the BigScience Project.\n",
    "They were obtained using the `jobs_info.py` script.\n",
    "\n",
    "## Data\n",
    "The logs can be found in the Project-end folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- Add GPU hours for each experiments, verify that it match quotas, extract total for main training\n",
    "- Add CPU hours for each experiments, verify that it match quotas\n",
    "- Add Histogram runs duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading, pre-processing and checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_l/bj8z3bgn341fz_btklx56xfr0000gq/T/ipykernel_2368/3972656704.py:13: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>num_V100_32GB</th>\n",
       "      <th>num_V100_16GB</th>\n",
       "      <th>num_A100_40GB</th>\n",
       "      <th>num_A100_80GB</th>\n",
       "      <th>alloc_cpu</th>\n",
       "      <th>alloc_mem</th>\n",
       "      <th>alloc_energy</th>\n",
       "      <th>partition</th>\n",
       "      <th>group</th>\n",
       "      <th>elapsed</th>\n",
       "      <th>qos</th>\n",
       "      <th>jobname</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>workdir</th>\n",
       "      <th>account</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>771344</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>100G</td>\n",
       "      <td>25561382.0</td>\n",
       "      <td>cpu_p1</td>\n",
       "      <td>genini01</td>\n",
       "      <td>18:37:03</td>\n",
       "      <td>qos_cpu-t4</td>\n",
       "      <td>preprocess_oscar</td>\n",
       "      <td>2022-01-04T11:48:15</td>\n",
       "      <td>2022-01-05T06:25:18</td>\n",
       "      <td>/gpfsdswork/projects/rech/rcy/ulz63oj/BigScience-experiments</td>\n",
       "      <td>six@cpu</td>\n",
       "      <td>2022_08_24_roman_castagne_logs.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>772361</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cpu_p1</td>\n",
       "      <td>genini01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>qos_cpu-t4</td>\n",
       "      <td>preprocess_oscar</td>\n",
       "      <td>2022-01-04T14:22:30</td>\n",
       "      <td>2022-01-04T14:22:30</td>\n",
       "      <td>/gpfsdswork/projects/rech/rcy/ulz63oj/BigScience-experiments</td>\n",
       "      <td>six@cpu</td>\n",
       "      <td>2022_08_24_roman_castagne_logs.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>772368</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cpu_p1</td>\n",
       "      <td>genini01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>qos_cpu-t4</td>\n",
       "      <td>preprocess_oscar</td>\n",
       "      <td>2022-01-04T14:23:51</td>\n",
       "      <td>2022-01-04T14:23:51</td>\n",
       "      <td>/gpfsdswork/projects/rech/rcy/ulz63oj/BigScience-experiments</td>\n",
       "      <td>six@cpu</td>\n",
       "      <td>2022_08_24_roman_castagne_logs.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   job_id  num_V100_32GB  num_V100_16GB  num_A100_40GB  num_A100_80GB  \\\n",
       "0  771344  0              0              0              0               \n",
       "1  772361  0              0              0              0               \n",
       "2  772368  0              0              0              0               \n",
       "\n",
       "   alloc_cpu alloc_mem  alloc_energy partition     group   elapsed  \\\n",
       "0  50.0       100G      25561382.0    cpu_p1    genini01  18:37:03   \n",
       "1 NaN         NaN      NaN            cpu_p1    genini01  00:00:00   \n",
       "2 NaN         NaN      NaN            cpu_p1    genini01  00:00:00   \n",
       "\n",
       "          qos           jobname                start                  end  \\\n",
       "0  qos_cpu-t4  preprocess_oscar  2022-01-04T11:48:15  2022-01-05T06:25:18   \n",
       "1  qos_cpu-t4  preprocess_oscar  2022-01-04T14:22:30  2022-01-04T14:22:30   \n",
       "2  qos_cpu-t4  preprocess_oscar  2022-01-04T14:23:51  2022-01-04T14:23:51   \n",
       "\n",
       "                                                        workdir  account  \\\n",
       "0  /gpfsdswork/projects/rech/rcy/ulz63oj/BigScience-experiments  six@cpu   \n",
       "1  /gpfsdswork/projects/rech/rcy/ulz63oj/BigScience-experiments  six@cpu   \n",
       "2  /gpfsdswork/projects/rech/rcy/ulz63oj/BigScience-experiments  six@cpu   \n",
       "\n",
       "                                 file  \n",
       "0  2022_08_24_roman_castagne_logs.txt  \n",
       "1  2022_08_24_roman_castagne_logs.txt  \n",
       "2  2022_08_24_roman_castagne_logs.txt  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read files into a single DataFrame\n",
    "directory = \"Project-end/\"\n",
    "file_paths = [directory+x for x in os.listdir(directory) if x.endswith(\"logs.txt\")]\n",
    "df_list = [pd.read_csv(filename, sep=\"|\", header=None).assign(file=filename.split(\"/\")[1]) for filename in file_paths]\n",
    "df = pd.concat(df_list)\n",
    "df.columns= ['job_id', 'num_V100_32GB', 'num_V100_16GB', 'num_A100_40GB', 'num_A100_80GB', \\\n",
    "             'alloc_cpu', 'alloc_mem', 'alloc_energy', 'partition', 'group', 'elapsed',\\\n",
    "              'qos','jobname', 'start', 'end', 'workdir', 'account' ,'file']\n",
    "\n",
    "# Set display\n",
    "pd.set_option('display.max_columns', 1000)  # or 1000\n",
    "pd.set_option('display.max_rows', 1000)  # or 1000\n",
    "pd.set_option('display.max_colwidth', -1) \n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>num_V100_32GB</th>\n",
       "      <th>num_V100_16GB</th>\n",
       "      <th>num_A100_40GB</th>\n",
       "      <th>num_A100_80GB</th>\n",
       "      <th>alloc_cpu</th>\n",
       "      <th>alloc_mem</th>\n",
       "      <th>partition</th>\n",
       "      <th>group</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>elapsed</th>\n",
       "      <th>duration</th>\n",
       "      <th>duration_diff</th>\n",
       "      <th>qos</th>\n",
       "      <th>jobname</th>\n",
       "      <th>account</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>783484</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4G</td>\n",
       "      <td>cpu_p1</td>\n",
       "      <td>genini01</td>\n",
       "      <td>2022-01-05 11:31:44</td>\n",
       "      <td>2022-01-06 13:30:08</td>\n",
       "      <td>-5 days +18:01:36</td>\n",
       "      <td>1 days 01:58:24</td>\n",
       "      <td>5 days 07:56:48</td>\n",
       "      <td>qos_cpu-t4</td>\n",
       "      <td>preprocess_oscar</td>\n",
       "      <td>six@cpu</td>\n",
       "      <td>2022_08_24_roman_castagne_logs.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>783489</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4G</td>\n",
       "      <td>cpu_p1</td>\n",
       "      <td>genini01</td>\n",
       "      <td>2022-01-05 11:31:44</td>\n",
       "      <td>2022-01-06 13:30:08</td>\n",
       "      <td>-5 days +18:01:36</td>\n",
       "      <td>1 days 01:58:24</td>\n",
       "      <td>5 days 07:56:48</td>\n",
       "      <td>qos_cpu-t4</td>\n",
       "      <td>preprocess_oscar</td>\n",
       "      <td>six@cpu</td>\n",
       "      <td>2022_08_24_roman_castagne_logs.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>783491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4G</td>\n",
       "      <td>cpu_p1</td>\n",
       "      <td>genini01</td>\n",
       "      <td>2022-01-05 11:31:44</td>\n",
       "      <td>2022-01-06 13:30:08</td>\n",
       "      <td>-5 days +18:01:36</td>\n",
       "      <td>1 days 01:58:24</td>\n",
       "      <td>5 days 07:56:48</td>\n",
       "      <td>qos_cpu-t4</td>\n",
       "      <td>preprocess_oscar</td>\n",
       "      <td>six@cpu</td>\n",
       "      <td>2022_08_24_roman_castagne_logs.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   job_id  num_V100_32GB  num_V100_16GB  num_A100_40GB  num_A100_80GB  \\\n",
       "7  783484  0              0              0              0               \n",
       "8  783489  0              0              0              0               \n",
       "9  783491  0              0              0              0               \n",
       "\n",
       "   alloc_cpu alloc_mem partition     group               start  \\\n",
       "7  2.0        4G        cpu_p1    genini01 2022-01-05 11:31:44   \n",
       "8  2.0        4G        cpu_p1    genini01 2022-01-05 11:31:44   \n",
       "9  2.0        4G        cpu_p1    genini01 2022-01-05 11:31:44   \n",
       "\n",
       "                  end           elapsed        duration   duration_diff  \\\n",
       "7 2022-01-06 13:30:08 -5 days +18:01:36 1 days 01:58:24 5 days 07:56:48   \n",
       "8 2022-01-06 13:30:08 -5 days +18:01:36 1 days 01:58:24 5 days 07:56:48   \n",
       "9 2022-01-06 13:30:08 -5 days +18:01:36 1 days 01:58:24 5 days 07:56:48   \n",
       "\n",
       "          qos           jobname  account                                file  \n",
       "7  qos_cpu-t4  preprocess_oscar  six@cpu  2022_08_24_roman_castagne_logs.txt  \n",
       "8  qos_cpu-t4  preprocess_oscar  six@cpu  2022_08_24_roman_castagne_logs.txt  \n",
       "9  qos_cpu-t4  preprocess_oscar  six@cpu  2022_08_24_roman_castagne_logs.txt  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete useless fields\n",
    "df=df.drop(['alloc_energy','workdir'], axis=1)\n",
    "\n",
    "# Cast datetimes as such\n",
    "df['start'] = pd.to_datetime(df['start'])\n",
    "df['end'] = pd.to_datetime(df['end'],  errors='coerce')\n",
    "\n",
    "# We are going to make our own duration as elapsed field is sometimes buggy\n",
    "df['elapsed'] = pd.to_timedelta(df['elapsed'])\n",
    "df['duration'] = df['end'] - df['start']\n",
    "df['duration_diff']= df['duration'] - df['elapsed']\n",
    "\n",
    "# Hacky columns re-arrange\n",
    "df=df[df.columns[[0,1,2,3,4,5,6,7,8,12,13,9,16,17,10,11,14,15]]] \n",
    "\n",
    "# Show example of elapsed time being bogus\n",
    "df[df['duration_diff']>pd.to_timedelta(0)].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>num_V100_32GB</th>\n",
       "      <th>num_V100_16GB</th>\n",
       "      <th>num_A100_40GB</th>\n",
       "      <th>num_A100_80GB</th>\n",
       "      <th>alloc_cpu</th>\n",
       "      <th>alloc_mem</th>\n",
       "      <th>partition</th>\n",
       "      <th>group</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>elapsed</th>\n",
       "      <th>duration</th>\n",
       "      <th>duration_diff</th>\n",
       "      <th>qos</th>\n",
       "      <th>jobname</th>\n",
       "      <th>account</th>\n",
       "      <th>file</th>\n",
       "      <th>hours_V100_32GB</th>\n",
       "      <th>hours_V100_16GB</th>\n",
       "      <th>hours_A100_40GB</th>\n",
       "      <th>hours_A100_80GB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>662615</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>128.0</td>\n",
       "      <td>480000M</td>\n",
       "      <td>gpu_p5</td>\n",
       "      <td>six</td>\n",
       "      <td>2022-03-22 22:37:39</td>\n",
       "      <td>2022-03-22 23:09:43</td>\n",
       "      <td>0 days 00:32:04</td>\n",
       "      <td>0 days 00:32:04</td>\n",
       "      <td>0 days</td>\n",
       "      <td>qos_gpu-t3</td>\n",
       "      <td>bash</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022_08_24_thomwolf_jz_logs.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.275556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2184</th>\n",
       "      <td>406772</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>384</td>\n",
       "      <td>6144.0</td>\n",
       "      <td>22500G</td>\n",
       "      <td>gpu_p5</td>\n",
       "      <td>genhug01</td>\n",
       "      <td>2022-06-12 00:31:16</td>\n",
       "      <td>2022-06-12 00:31:17</td>\n",
       "      <td>0 days 00:00:01</td>\n",
       "      <td>0 days 00:00:01</td>\n",
       "      <td>0 days</td>\n",
       "      <td>qos_gpu-gc</td>\n",
       "      <td>tr11-176B-ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>new_hugo_laurencon_jz_logs.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4801</th>\n",
       "      <td>1677884</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22500M</td>\n",
       "      <td>gpu_p5</td>\n",
       "      <td>genltc01</td>\n",
       "      <td>2022-07-29 19:59:56</td>\n",
       "      <td>2022-07-29 20:00:22</td>\n",
       "      <td>0 days 00:00:26</td>\n",
       "      <td>0 days 00:00:26</td>\n",
       "      <td>0 days</td>\n",
       "      <td>qos_gpu-t3</td>\n",
       "      <td>training</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022_08_01_pierrec_jz_logs.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       job_id  num_V100_32GB  num_V100_16GB  num_A100_40GB  num_A100_80GB  \\\n",
       "758   662615   0              0              0              8               \n",
       "2184  406772   0              0              0              384             \n",
       "4801  1677884  0              0              0              1               \n",
       "\n",
       "      alloc_cpu alloc_mem partition     group               start  \\\n",
       "758   128.0      480000M   gpu_p5    six      2022-03-22 22:37:39   \n",
       "2184  6144.0     22500G    gpu_p5    genhug01 2022-06-12 00:31:16   \n",
       "4801  6.0        22500M    gpu_p5    genltc01 2022-07-29 19:59:56   \n",
       "\n",
       "                     end         elapsed        duration duration_diff  \\\n",
       "758  2022-03-22 23:09:43 0 days 00:32:04 0 days 00:32:04 0 days          \n",
       "2184 2022-06-12 00:31:17 0 days 00:00:01 0 days 00:00:01 0 days          \n",
       "4801 2022-07-29 20:00:22 0 days 00:00:26 0 days 00:00:26 0 days          \n",
       "\n",
       "             qos       jobname account                             file  \\\n",
       "758   qos_gpu-t3  bash          NaN     2022_08_24_thomwolf_jz_logs.txt   \n",
       "2184  qos_gpu-gc  tr11-176B-ml  NaN     new_hugo_laurencon_jz_logs.txt    \n",
       "4801  qos_gpu-t3  training      NaN     2022_08_01_pierrec_jz_logs.txt    \n",
       "\n",
       "      hours_V100_32GB  hours_V100_16GB  hours_A100_40GB  hours_A100_80GB  \n",
       "758   0.0              0.0              0.0              4.275556         \n",
       "2184  0.0              0.0              0.0              0.106667         \n",
       "4801  0.0              0.0              0.0              0.007222         "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute GPU hours per hardware type\n",
    "durations_in_hours = (df['duration'] / np.timedelta64(1, 's') / 3600)\n",
    "df['hours_V100_32GB'] = df['num_V100_32GB'] * durations_in_hours\n",
    "df['hours_V100_16GB'] = df['num_V100_16GB'] * durations_in_hours\n",
    "df['hours_A100_40GB'] = df['num_A100_40GB'] * durations_in_hours\n",
    "df['hours_A100_80GB'] = df['num_A100_80GB'] * durations_in_hours\n",
    "df[df['hours_A100_80GB']>0].head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1242577.3975"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.hours_A100_80GB.sum() # Capturing 99.3% of quotas, looking fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2363314.7327777776"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.hours_V100_32GB.sum() + df.hours_V100_16GB.sum() # Capturing 115% of quotas, maybe quotas does not count all partitions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gpu_p13    26142\n",
       "gpu_p2     8338 \n",
       "gpu_p2l    31   \n",
       "gpu_p2s    25   \n",
       "Name: partition, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_v100 = df[(df['hours_V100_32GB']>0) | (df['hours_V100_16GB']>0)]\n",
    "df_v100.partition.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>num_V100_32GB</th>\n",
       "      <th>num_V100_16GB</th>\n",
       "      <th>num_A100_40GB</th>\n",
       "      <th>num_A100_80GB</th>\n",
       "      <th>alloc_cpu</th>\n",
       "      <th>alloc_mem</th>\n",
       "      <th>partition</th>\n",
       "      <th>group</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>elapsed</th>\n",
       "      <th>duration</th>\n",
       "      <th>duration_diff</th>\n",
       "      <th>qos</th>\n",
       "      <th>jobname</th>\n",
       "      <th>account</th>\n",
       "      <th>file</th>\n",
       "      <th>hours_V100_32GB</th>\n",
       "      <th>hours_V100_16GB</th>\n",
       "      <th>hours_A100_40GB</th>\n",
       "      <th>hours_A100_80GB</th>\n",
       "      <th>gpu_power_watts_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1127041</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>2.50T</td>\n",
       "      <td>gpu_p13</td>\n",
       "      <td>six</td>\n",
       "      <td>2022-01-13 05:54:05</td>\n",
       "      <td>2022-01-13 06:22:04</td>\n",
       "      <td>0 days 00:27:59</td>\n",
       "      <td>0 days 00:27:59</td>\n",
       "      <td>0 days</td>\n",
       "      <td>qos_gpu-t3</td>\n",
       "      <td>mbert_alpha</td>\n",
       "      <td>six@gpu</td>\n",
       "      <td>2022_08_24_roman_castagne_logs.txt</td>\n",
       "      <td>29.848889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8954.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1308991</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>2.50T</td>\n",
       "      <td>gpu_p13</td>\n",
       "      <td>six</td>\n",
       "      <td>2022-01-17 16:31:47</td>\n",
       "      <td>2022-01-17 16:35:37</td>\n",
       "      <td>0 days 00:03:50</td>\n",
       "      <td>0 days 00:03:50</td>\n",
       "      <td>0 days</td>\n",
       "      <td>qos_gpu-t3</td>\n",
       "      <td>mbert_alpha</td>\n",
       "      <td>six@gpu</td>\n",
       "      <td>2022_08_24_roman_castagne_logs.txt</td>\n",
       "      <td>4.088889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1226.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1314956</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>160G</td>\n",
       "      <td>gpu_p13</td>\n",
       "      <td>six</td>\n",
       "      <td>2022-01-17 18:29:49</td>\n",
       "      <td>2022-01-18 04:30:18</td>\n",
       "      <td>0 days 10:00:29</td>\n",
       "      <td>0 days 10:00:29</td>\n",
       "      <td>0 days</td>\n",
       "      <td>qos_gpu-t3</td>\n",
       "      <td>mbert_alpha</td>\n",
       "      <td>six@gpu</td>\n",
       "      <td>2022_08_24_roman_castagne_logs.txt</td>\n",
       "      <td>40.032222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12009.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     job_id  num_V100_32GB  num_V100_16GB  num_A100_40GB  num_A100_80GB  \\\n",
       "18  1127041  64             0              0              0               \n",
       "21  1308991  64             0              0              0               \n",
       "22  1314956  4              0              0              0               \n",
       "\n",
       "    alloc_cpu alloc_mem partition group               start  \\\n",
       "18  1280.0     2.50T     gpu_p13   six  2022-01-13 05:54:05   \n",
       "21  1280.0     2.50T     gpu_p13   six  2022-01-17 16:31:47   \n",
       "22  80.0       160G      gpu_p13   six  2022-01-17 18:29:49   \n",
       "\n",
       "                   end         elapsed        duration duration_diff  \\\n",
       "18 2022-01-13 06:22:04 0 days 00:27:59 0 days 00:27:59 0 days          \n",
       "21 2022-01-17 16:35:37 0 days 00:03:50 0 days 00:03:50 0 days          \n",
       "22 2022-01-18 04:30:18 0 days 10:00:29 0 days 10:00:29 0 days          \n",
       "\n",
       "           qos      jobname  account                                file  \\\n",
       "18  qos_gpu-t3  mbert_alpha  six@gpu  2022_08_24_roman_castagne_logs.txt   \n",
       "21  qos_gpu-t3  mbert_alpha  six@gpu  2022_08_24_roman_castagne_logs.txt   \n",
       "22  qos_gpu-t3  mbert_alpha  six@gpu  2022_08_24_roman_castagne_logs.txt   \n",
       "\n",
       "    hours_V100_32GB  hours_V100_16GB  hours_A100_40GB  hours_A100_80GB  \\\n",
       "18  29.848889        0.0              0.0              0.0               \n",
       "21  4.088889         0.0              0.0              0.0               \n",
       "22  40.032222        0.0              0.0              0.0               \n",
       "\n",
       "    gpu_power_watts_hours  \n",
       "18  8954.666667            \n",
       "21  1226.666667            \n",
       "22  12009.666667           "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute GPU power for each job, assuming running at 100% TDP, using hardware info from JZ documentation --> http://www.idris.fr/eng/jean-zay/cpu/jean-zay-cpu-hw-eng.html\n",
    "df['gpu_power_watts_hours'] = df['hours_V100_32GB'] * 300 # https://resources.nvidia.com/en-us-virtualization-and-gpus/v100-datasheet\n",
    "df['gpu_power_watts_hours'] += df['hours_V100_16GB'] * 300 # https://resources.nvidia.com/en-us-virtualization-and-gpus/v100-datasheet\n",
    "df['gpu_power_watts_hours'] += df['hours_A100_40GB'] * 250 # https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/A100-PCIE-Prduct-Brief.pdf\n",
    "df['gpu_power_watts_hours'] += df['hours_A100_80GB'] * 400 # https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/nvidia-a100-datasheet-nvidia-us-2188504-web.pdf\n",
    "\n",
    "df[df['gpu_power_watts_hours']>0].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>num_V100_32GB</th>\n",
       "      <th>num_V100_16GB</th>\n",
       "      <th>num_A100_40GB</th>\n",
       "      <th>num_A100_80GB</th>\n",
       "      <th>alloc_cpu</th>\n",
       "      <th>alloc_mem</th>\n",
       "      <th>partition</th>\n",
       "      <th>group</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>elapsed</th>\n",
       "      <th>duration</th>\n",
       "      <th>duration_diff</th>\n",
       "      <th>qos</th>\n",
       "      <th>jobname</th>\n",
       "      <th>account</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41517</th>\n",
       "      <td>726762</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>384</td>\n",
       "      <td>6144.0</td>\n",
       "      <td>22500G</td>\n",
       "      <td>gpu_p5</td>\n",
       "      <td>six</td>\n",
       "      <td>2022-03-25 11:09:19</td>\n",
       "      <td>2022-03-28 11:14:56</td>\n",
       "      <td>-10 days +16:54:23</td>\n",
       "      <td>3 days 00:05:37</td>\n",
       "      <td>12 days 07:11:14</td>\n",
       "      <td>qos_gpu-gc</td>\n",
       "      <td>tr11-176B-ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022_08_02_thomas_wang_jz_logs.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       job_id  num_V100_32GB  num_V100_16GB  num_A100_40GB  num_A100_80GB  \\\n",
       "41517  726762  0              0              0              384             \n",
       "\n",
       "       alloc_cpu alloc_mem partition group               start  \\\n",
       "41517  6144.0     22500G    gpu_p5    six  2022-03-25 11:09:19   \n",
       "\n",
       "                      end            elapsed        duration    duration_diff  \\\n",
       "41517 2022-03-28 11:14:56 -10 days +16:54:23 3 days 00:05:37 12 days 07:11:14   \n",
       "\n",
       "              qos       jobname account                                file  \n",
       "41517  qos_gpu-gc  tr11-176B-ml  NaN     2022_08_02_thomas_wang_jz_logs.txt  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['job_id']=='726762']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0 days 18:37:03\n",
       "1       0 days 00:00:00\n",
       "2       0 days 00:00:00\n",
       "3       0 days 22:55:58\n",
       "4       0 days 06:26:29\n",
       "              ...      \n",
       "39026   0 days 00:09:47\n",
       "39027   0 days 00:11:51\n",
       "39028   0 days 00:20:09\n",
       "39029   0 days 00:20:54\n",
       "39030   0 days 00:10:45\n",
       "Name: duration, Length: 177192, dtype: timedelta64[ns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('5816 days 13:22:40')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['duration'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2022_08_02_thomas_wang_jz_logs.txt      45967\n",
       "2022_08_08_luciles_logs.txt             39031\n",
       "2022_08_01_stas_jz_logs.txt             38111\n",
       "2022_08_25_victorsanh_jz_logs.txt       29049\n",
       "2022-08-24_tvn_jz_logs.txt              11385\n",
       "2022_08_01_muennighoff_jz_logs.txt      5139 \n",
       "2022_08_01_pierrec_jz_logs.txt          4813 \n",
       "new_hugo_laurencon_jz_logs.txt          2185 \n",
       "2022_08_24_thomwolf_jz_logs.txt         760  \n",
       "2022_08_02_younesb_jz_logs.txt          603  \n",
       "2022_08_24_roman_castagne_logs.txt      110  \n",
       "2022_08_01_sylvainv_jz_logs.txt         34   \n",
       "2022_08_08_danielhesslow_jz_logs.txt    5    \n",
       "Name: file, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['file'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Bloom Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>num_V100_32GB</th>\n",
       "      <th>num_V100_16GB</th>\n",
       "      <th>num_A100_40GB</th>\n",
       "      <th>num_A100_80GB</th>\n",
       "      <th>alloc_cpu</th>\n",
       "      <th>alloc_mem</th>\n",
       "      <th>partition</th>\n",
       "      <th>group</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>elapsed</th>\n",
       "      <th>duration</th>\n",
       "      <th>duration_diff</th>\n",
       "      <th>qos</th>\n",
       "      <th>jobname</th>\n",
       "      <th>account</th>\n",
       "      <th>file</th>\n",
       "      <th>hours_V100_32GB</th>\n",
       "      <th>hours_V100_16GB</th>\n",
       "      <th>hours_A100_40GB</th>\n",
       "      <th>hours_A100_80GB</th>\n",
       "      <th>gpu_power_watts_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2184</th>\n",
       "      <td>406772</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>384</td>\n",
       "      <td>6144.0</td>\n",
       "      <td>22500G</td>\n",
       "      <td>gpu_p5</td>\n",
       "      <td>genhug01</td>\n",
       "      <td>2022-06-12 00:31:16</td>\n",
       "      <td>2022-06-12 00:31:17</td>\n",
       "      <td>0 days 00:00:01</td>\n",
       "      <td>0 days 00:00:01</td>\n",
       "      <td>0 days</td>\n",
       "      <td>qos_gpu-gc</td>\n",
       "      <td>tr11-176B-ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>new_hugo_laurencon_jz_logs.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>42.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41501</th>\n",
       "      <td>417634</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>384</td>\n",
       "      <td>6144.0</td>\n",
       "      <td>22500G</td>\n",
       "      <td>gpu_p5</td>\n",
       "      <td>six</td>\n",
       "      <td>2022-03-11 18:09:15</td>\n",
       "      <td>2022-03-11 18:11:04</td>\n",
       "      <td>0 days 00:01:49</td>\n",
       "      <td>0 days 00:01:49</td>\n",
       "      <td>0 days</td>\n",
       "      <td>qos_gpu-gc</td>\n",
       "      <td>tr11-176B-ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022_08_02_thomas_wang_jz_logs.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.626667</td>\n",
       "      <td>4650.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41502</th>\n",
       "      <td>417716</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>384</td>\n",
       "      <td>6144.0</td>\n",
       "      <td>22500G</td>\n",
       "      <td>gpu_p5</td>\n",
       "      <td>six</td>\n",
       "      <td>2022-03-11 18:18:33</td>\n",
       "      <td>2022-03-11 18:20:04</td>\n",
       "      <td>0 days 00:01:31</td>\n",
       "      <td>0 days 00:01:31</td>\n",
       "      <td>0 days</td>\n",
       "      <td>qos_gpu-gc</td>\n",
       "      <td>tr11-176B-ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022_08_02_thomas_wang_jz_logs.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.706667</td>\n",
       "      <td>3882.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       job_id  num_V100_32GB  num_V100_16GB  num_A100_40GB  num_A100_80GB  \\\n",
       "2184   406772  0              0              0              384             \n",
       "41501  417634  0              0              0              384             \n",
       "41502  417716  0              0              0              384             \n",
       "\n",
       "       alloc_cpu alloc_mem partition     group               start  \\\n",
       "2184   6144.0     22500G    gpu_p5    genhug01 2022-06-12 00:31:16   \n",
       "41501  6144.0     22500G    gpu_p5    six      2022-03-11 18:09:15   \n",
       "41502  6144.0     22500G    gpu_p5    six      2022-03-11 18:18:33   \n",
       "\n",
       "                      end         elapsed        duration duration_diff  \\\n",
       "2184  2022-06-12 00:31:17 0 days 00:00:01 0 days 00:00:01 0 days          \n",
       "41501 2022-03-11 18:11:04 0 days 00:01:49 0 days 00:01:49 0 days          \n",
       "41502 2022-03-11 18:20:04 0 days 00:01:31 0 days 00:01:31 0 days          \n",
       "\n",
       "              qos       jobname account                                file  \\\n",
       "2184   qos_gpu-gc  tr11-176B-ml  NaN     new_hugo_laurencon_jz_logs.txt       \n",
       "41501  qos_gpu-gc  tr11-176B-ml  NaN     2022_08_02_thomas_wang_jz_logs.txt   \n",
       "41502  qos_gpu-gc  tr11-176B-ml  NaN     2022_08_02_thomas_wang_jz_logs.txt   \n",
       "\n",
       "       hours_V100_32GB  hours_V100_16GB  hours_A100_40GB  hours_A100_80GB  \\\n",
       "2184   0.0              0.0              0.0              0.106667          \n",
       "41501  0.0              0.0              0.0              11.626667         \n",
       "41502  0.0              0.0              0.0              9.706667          \n",
       "\n",
       "       gpu_power_watts_hours  \n",
       "2184   42.666667              \n",
       "41501  4650.666667            \n",
       "41502  3882.666667            "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select only final training runs\n",
    "bloomdf = df[df['jobname'] == 'tr11-176B-ml']\n",
    "bloomdf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384    316\n",
       "192    27 \n",
       "0      20 \n",
       "144    13 \n",
       "288    8  \n",
       "1      5  \n",
       "32     4  \n",
       "8      2  \n",
       "16     2  \n",
       "216    1  \n",
       "Name: num_A100_80GB, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bloomdf['num_A100_80GB'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('118 days 05:40:42')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bloomdf.duration.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1082989.4766666668"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bloomdf.hours_A100_80GB.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "433195.79066666664"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bloomdf.gpu_power_watts_hours.sum() / 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Trainings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6430, 18)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf = df[df['jobname'].str.startswith('tr')]\n",
    "traindf = traindf[traindf['jobname'] != 'tr11-176B-ml']\n",
    "traindf = traindf[~traindf['jobname'].str.contains('sync')]\n",
    "traindf = traindf[~traindf['jobname'].str.contains('slurm')]\n",
    "traindf = traindf[~traindf['jobname'].str.contains('move')]\n",
    "traindf = traindf[~traindf['jobname'].str.contains('eval')]\n",
    "traindf = traindf[~traindf['jobname'].str.contains('tokenizer')]\n",
    "traindf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tr6e-1B3-prefix-lm                                        1435\n",
       "tr6f-1B3-prefix-lm                                        1431\n",
       "tr6g-1B3-prefix-lm                                        1008\n",
       "tr7d-1B3-alibi                                            433 \n",
       "tr11                                                      302 \n",
       "tr11-200B-ml                                              204 \n",
       "tr8-104B                                                  153 \n",
       "tr11f-6B3-ml                                              146 \n",
       "tr8b-104B-cl                                              131 \n",
       "tr8b-104B-bnb                                             123 \n",
       "tr8b-104B-emb-norm                                        117 \n",
       "tr13f-6B3-ml-t0                                           102 \n",
       "tr5c-1B3-multilingual-alpha-alibi                         81  \n",
       "tr11c-2B5-ml                                              78  \n",
       "tr5d-1B3-multilingual-equal-alibi                         73  \n",
       "tr11e-350M-ml                                             72  \n",
       "tr1-13B-round3                                            70  \n",
       "tr11d-760M-ml                                             69  \n",
       "tr11b-1B3-ml                                              63  \n",
       "tr8b-104B-cl-a100                                         50  \n",
       "tr8b-104B                                                 46  \n",
       "tr5b-1B3-multilingual-alpha                               42  \n",
       "tr7d-1B3-modeling-alibi-fp16                              21  \n",
       "tr8-104B-data-study-data-with-many-slashes                14  \n",
       "tr8b-104B-pile                                            14  \n",
       "tr13f-6B3-ml-t0-memcheck                                  14  \n",
       "tr7d-1B3-modeling-alibi-bf16                              12  \n",
       "tr8-104B-mt5                                              12  \n",
       "training                                                  12  \n",
       "tr11-176B-ml-spike                                        12  \n",
       "tr11e-350M-ml-t0                                          11  \n",
       "tr11f-6B3-ml-universal                                    8   \n",
       "tr11-176B-ml-universal                                    6   \n",
       "train_tokenize_v2_toy                                     5   \n",
       "tr11b-1B3-ml-swiglu-a                                     5   \n",
       "tr8b-104B-emb-norm-a100-bf16                              4   \n",
       "train_tokenize_v2                                         4   \n",
       "tr8-104B-tp4-pp32-bs1024                                  3   \n",
       "tr11e-350M-ml-continue-old                                3   \n",
       "tr8-104B-tp4-pp16-bs1024                                  3   \n",
       "tr8-104B-data-study-data-no-basic-junk                    3   \n",
       "tr8-104B-tp4-pp64-bs1024                                  3   \n",
       "tr8-104B-tp4-pp32-bs2048                                  2   \n",
       "tr8-104B-tp4-pp32                                         2   \n",
       "tr11b-1B3-ml-noswiglu                                     2   \n",
       "tr11b-1B3-ml-swiglu                                       2   \n",
       "tr7d-1B3-modeling-alibi-fp16-rampup                       2   \n",
       "tr11-200B-ml-2                                            2   \n",
       "tr11e-350M-ml-zero1                                       2   \n",
       "tr11e-350M-ml-swiglu                                      2   \n",
       "tr11e-350M-ml-noswiglu                                    1   \n",
       "tr8-104B-tp4-pp16                                         1   \n",
       "tr11b-1B3-ml-noswiglu-a                                   1   \n",
       "tr8-104B-tp4-pp8                                          1   \n",
       "tr5c-1B3-multilingual-equal-alibi                         1   \n",
       "trex_bs2560_hard_neg                                      1   \n",
       "tr8-104B-data-study-data-basic-junk-and-low-stopwords2    1   \n",
       "tr8-104B-data-study-data-basic-junk-and-low-stopwords     1   \n",
       "tr7d-1B3-modeling-alibi-bf16-rampup                       1   \n",
       "tr8-104B-data-study-TEMPLATE                              1   \n",
       "tr8-104B-data-study-data-basic-junk                       1   \n",
       "tr5b-1B3-multilingual-alpha-16                            1   \n",
       "tr8-104B-data-study-data-junk-with-stopwords              1   \n",
       "tr8-104B-data-study-data-with-only-slashes                1   \n",
       "tr8-104B-data-study-data-basic-junk-only2                 1   \n",
       "tr8-104B-data-study-data-basic-junk-only                  1   \n",
       "Name: jobname, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf['jobname'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('488 days 13:34:21')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.duration.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16041, 18)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaldf = df[df['jobname'].str.contains('eval')]\n",
    "evaldf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eval-tr3                                                                            3643\n",
       "evaluate_t0                                                                         2337\n",
       "eval_finetune-t5-xxl-lm-d4-091621                                                   747 \n",
       "score_eval_finetune-t5-xxl-lm-d4-091621                                             694 \n",
       "score_eval_finetune-t5-xxl-lm-d4-all-091621                                         671 \n",
       "eval_baseline                                                                       534 \n",
       "eval_finetune-t5-xxl-lm-d4-all-091621                                               531 \n",
       "eval_finetune-t5-xl-lm-d4-091621                                                    530 \n",
       "eval_finetune-t5-xxl-lm-d4-091621-512                                               530 \n",
       "eval_finetune-t5-xxl-lm-d4-gpt-091621                                               514 \n",
       "bs-eval-bloom-176b                                                                  504 \n",
       "score_eval_finetune-t5-xxl-lm-d4-og-091621                                          446 \n",
       "score_eval_finetune-t5-xl-lm-d4-091621                                              446 \n",
       "score_eval_finetune-t5-xxl-lm-d4-091621-512                                         446 \n",
       "score_eval_finetune-t5-xxl-lm-d4-gpt-091621                                         446 \n",
       "bs-eval-opt-175b                                                                    397 \n",
       "eai-eval                                                                            396 \n",
       "tr3n_harness_eval                                                                   324 \n",
       "eval                                                                                267 \n",
       "eval_finetune-t5-xxl-lm-d4-og-091621                                                265 \n",
       "score_eval_finetune-t5-xxl-lm-d4-all-og-091621                                      231 \n",
       "score_eval                                                                          128 \n",
       "eai-eval-opt-175b                                                                   127 \n",
       "biasfairness_evaluate                                                               116 \n",
       "run_evalharness-tr11-176B-a100-p1-muennighoff                                       73  \n",
       "run_evalharness-tr11-176B-a100                                                      48  \n",
       "bseval-tr13f-6B3                                                                    48  \n",
       "eai-eval-bloom-176b                                                                 48  \n",
       "run_evalharness-tr11-176b-ml                                                        44  \n",
       "tr3n_checkpoints_harness_eval                                                       32  \n",
       "eai-eval-opt-125m                                                                   26  \n",
       "tr3n_vs_tr3o_harness_eval                                                           26  \n",
       "tr3n_with_eosharness_eval                                                           25  \n",
       "run_evalharness-tr11-176b-ml-muennighoff                                            23  \n",
       "run_evalharness-tr13f-6B3-prefix                                                    20  \n",
       "tr13-base-eval                                                                      20  \n",
       "tr7b-350M-alibi-eval-1-seq-len.slurm                                                20  \n",
       "tr7a-1B3-alibi-eval                                                                 17  \n",
       "eval-array                                                                          17  \n",
       "run_evalharness-tr11-350M-ml                                                        15  \n",
       "eval-opt                                                                            14  \n",
       "lm-eval-tr5b-1B3-multilingual-alpha                                                 14  \n",
       "lm-eval-tr4c-1B3-rotary                                                             12  \n",
       "modelling-metadata-html-exp1-subexp1-evaluation-without-metadata                    12  \n",
       "run_bsevalharness-tr11e-350m-ml                                                     12  \n",
       "run_bsevalharness-tr11b-1b3-ml                                                      12  \n",
       "run_bsevalharness-tr11-176b-ml                                                      10  \n",
       "download_bs_eval                                                                    10  \n",
       "gpt_eval                                                                            9   \n",
       "thomas_run_evalharness-tr11-176b-ml                                                 9   \n",
       "run_evalharness-tr13f-6b3                                                           8   \n",
       "350M-alibi-check-eval-1-seq.slurm                                                   7   \n",
       "run_evalharness-tr11-176B-a100-p2                                                   7   \n",
       "run_evalharness-tr11c-6b3-ml                                                        7   \n",
       "eval_gpt_prefix_loss.slurm                                                          6   \n",
       "bs-eval-opt-125m                                                                    6   \n",
       "run_evalharness-tr11b-2b5-ml                                                        6   \n",
       "modelling-metadata-html-exp1-subexp2-evaluation-without-metadata                    6   \n",
       "eval_gpt_1B3_prefix_loss.slurm                                                      5   \n",
       "eval-harness-deepspeed                                                              5   \n",
       "lm-eval-swiglu                                                                      5   \n",
       "eval-bloom                                                                          5   \n",
       "eai-eval-opt                                                                        5   \n",
       "modelling-metadata-html-metadata-exp1-evaluation-without-metadata-create-dataset    5   \n",
       "tr3n_smoothed_harness_eval                                                          4   \n",
       "lm-eval-tr3m-1B3-emb-norm-pile                                                      4   \n",
       "lm-eval-tr3m-1B3-emb-norm                                                           4   \n",
       "run_bsevalharness-tr11c-2b5-ml                                                      4   \n",
       "350M-alibi-check-eval-2-seq.slurm                                                   4   \n",
       "run_evalharness-tr11d-760m-ml                                                       3   \n",
       "tr3n-1B3-pile-fancy-eval                                                            3   \n",
       "eval_gpt_rotary_prefix_loss.slurm                                                   3   \n",
       "bs-code-eval-bloom-176b                                                             3   \n",
       "run_bsevalharness-tr11b-2b5-ml                                                      3   \n",
       "run_evalharness-tr11-2B5-ml                                                         2   \n",
       "run_evalharness-tr11-1B3-ml                                                         2   \n",
       "eval-opt-int8-thresh-6                                                              2   \n",
       "run_evalharness-tr11e-350m-ml                                                       2   \n",
       "eval-bloom-bf16                                                                     2   \n",
       "eval-opt-fp16                                                                       2   \n",
       "eval-opt-int8                                                                       2   \n",
       "eval-harness-deepspeed-test                                                         2   \n",
       "lm-eval-tr7d-1B3-alibi-1                                                            2   \n",
       "run_bsevalharness-tr11-350M-ml                                                      2   \n",
       "run_evalharness-tr13c-6b3                                                           2   \n",
       "run_evalharness-tr11c-6b3-ml-169                                                    2   \n",
       "eval_finetune-t5-xxl-lm-d4-all-og-091621                                            1   \n",
       "lm-eval-tr4c-1B3-rotary-1                                                           1   \n",
       "lm-eval-tr7d-1B3-alibi                                                              1   \n",
       "download-bslmeval                                                                   1   \n",
       "eval-bloom-int8                                                                     1   \n",
       "bias_evaluate                                                                       1   \n",
       "eval-bloom-int8-thresh-0                                                            1   \n",
       "eval-bloom-int8-thresh-6                                                            1   \n",
       "eval-opt-fp16-4                                                                     1   \n",
       "run_evalharness-tr11-6B3-ml                                                         1   \n",
       "run_evalharness-tr11-760M-ml                                                        1   \n",
       "run_evalharness-tr11c-6b3                                                           1   \n",
       "tr4c-1B3-alibi-eval                                                                 1   \n",
       "Name: jobname, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaldf['jobname'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 18)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokendf = df[df['jobname'].str.contains('tokenizer')]\n",
    "tokendf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_tokenizer                                                 67\n",
       "modelling-metadata-example-load-model-and-tokenizer             11\n",
       "modelling-metadata-website-desc-load-model-and-tokenizer        8 \n",
       "modelling-metadata-html-download-tokenizer-and-model            6 \n",
       "compare_tokenizers                                              3 \n",
       "modelling-metadata-entity-beg-load-model-and-tokenizer          2 \n",
       "modelling-metadata-exp1-subexp3-load-model-and-tokenizer        2 \n",
       "modelling-metadata-entity-load-model-and-tokenizer              1 \n",
       "modelling-metadata-exp1-subexp1-load-model-and-tokenizer        1 \n",
       "modelling-metadata-exp1-subexp2-load-model-and-tokenizer        1 \n",
       "modelling-metadata-website-desc-load-model-and-tokenizer-25k    1 \n",
       "Name: jobname, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokendf['jobname'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PROCESSING, DOWNLOADING, DEDUPLICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29359, 18)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadf = df[df['jobname'].str.contains('data')]\n",
    "datadf = datadf[~datadf['jobname'].str.contains('token')]\n",
    "datadf.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "download_all_catalogue_datasets                                                     4507\n",
       "pseudo_crawl_clean_dataset                                                          4282\n",
       "preprocess_all_catalogue_datasets                                                   3146\n",
       "modelling-metadata-c4-dataset-toy-add-metadata-full                                 2925\n",
       "modelling-metadata-c4-dataset-toy-add-website-desc                                  2844\n",
       "modelling-metadata-c4-dataset-export-to-jsonlines                                   2801\n",
       "modelling-metadata-c4-dataset-toy-add-metadata-full-v3                              2761\n",
       "filter_short_document_all_catalogue_datasets                                        1900\n",
       "deduplicate_all_catalogue_datasets                                                  1121\n",
       "modelling-metadata-c4-dataset-toy-add-metadata-full-v2                              873 \n",
       "convert_datasets_to_jsonl                                                           609 \n",
       "yong-download_dataset                                                               373 \n",
       "modelling-metadata-c4-dataset-toy-add-metadata                                      159 \n",
       "modelling-metadata-c4-dataset-toy-add-metadata-timestamp                            125 \n",
       "modelling-metadata-c4-dataset-toy-add-metadata-entity                               80  \n",
       "modelling-metadata-c4-dataset-toy-add-metadata-url                                  80  \n",
       "modelling-metadata-c4-dataset-toy-add-metadata-website_description                  71  \n",
       "modelling-metadata-html-create-dataset-test                                         63  \n",
       "modelling-metadata-c4-dataset-toy-add-entities                                      62  \n",
       "modelling-metadata-html-do-train-test                                               32  \n",
       "modelling-metadata-c4-dataset-toy-add-metadata-html                                 30  \n",
       "modelling-metadata-sync-wandb                                                       26  \n",
       "tetraencoder_all_datasets                                                           23  \n",
       "download_dataset                                                                    20  \n",
       "preprocess_data_megatron                                                            18  \n",
       "modelling-metadata-example-load-dataset                                             17  \n",
       "modelling-metadata-joint-toy-1                                                      16  \n",
       "modelling-metadata-html-metadata-exp1-subexp1-transform-checkpoints                 16  \n",
       "modelling-metadata-html-metadata-exp1-subexp2-create-dataset                        14  \n",
       "tr8-104B-data-study-data-with-many-slashes                                          14  \n",
       "modelling-metadata-XX                                                               14  \n",
       "modelling-metadata-c4-dataset-toy-add-entities-cpu-2-bs-clip-max-num                13  \n",
       "modelling-metadata-html-download-dataset-test                                       12  \n",
       "modelling-metadata-html-exp1-subexp1-evaluation-without-metadata                    12  \n",
       "modelling-metadata-c4-dataset-create-toy                                            12  \n",
       "modelling-metadata-test-format                                                      12  \n",
       "load_dataset                                                                        11  \n",
       "dummy-data-processing                                                               10  \n",
       "modelling-metadata-c3-dataset-toy                                                   10  \n",
       "modelling-metadata-html-metadata-create-dataset                                     7   \n",
       "modelling-metadata-html-metadata-exp1-subexp1-create-dataset                        7   \n",
       "modelling-metadata-html-joint-toy-1                                                 6   \n",
       "sharding_dataset_fr                                                                 6   \n",
       "make_partial_bigscience_dataset                                                     6   \n",
       "modelling-metadata-c4-dataset-toy-add-entities-cpu-1-bs-clip-5000                   6   \n",
       "modelling-metadata-c4-dataset-toy-add-entities-cpu-1-bs-2-total-1000                6   \n",
       "modelling-metadata-html-create-toy-dataset                                          6   \n",
       "modelling-metadata-html-exp1-subexp2-evaluation-without-metadata                    6   \n",
       "modelling-metadata-c4-dataset-toy-add-entities-cpu-1-bs-1-total-1000                6   \n",
       "modelling-metadata-website-desc-create-dataset-25k                                  6   \n",
       "modelling-metadata-c4-dataset-toy-add-entities-cpu-2-bs-1-total-1000                6   \n",
       "reduce_all_datasets_options                                                         6   \n",
       "modelling-metadata-c4-dataset-toy-add-entities-cpu-2-bs-100-total-1000              6   \n",
       "modelling-metadata-c4-dataset-toy-add-entities-gpu-100                              6   \n",
       "modelling-metadata-c4-dataset-toy-add-entities-gpu-1000                             6   \n",
       "modelling-metadata-c4-dataset-toy-add-entities-gpu-2000                             6   \n",
       "modelling-metadata-c4-dataset-toy-add-entities-gpu                                  6   \n",
       "modelling-metadata-html-metadata-exp1-evaluation-without-metadata-create-dataset    5   \n",
       "modelling-metadata-html-exp1-subexp2-train                                          5   \n",
       "modelling-metadata-website-desc-load-dataset-25k                                    5   \n",
       "modelling-metadata-entity-beg-metadata-example-create-dataset                       5   \n",
       "pseudo_crawl_check_erros_in_dataset                                                 5   \n",
       "reduce_natural_questions_dataset                                                    5   \n",
       "modelling-metadata-dowload-wikipedia-dataset                                        4   \n",
       "modelling-metadata-html-joint_training_toy2-fp16                                    4   \n",
       "modelling-metadata-html-joint_training_toy3-fp16-multigpu                           4   \n",
       "modelling-metadata-html-example-train                                               4   \n",
       "preprocess_data_dedup_megatron                                                      4   \n",
       "convert_dataset_jsonl                                                               4   \n",
       "modelling-metadata-c4-dataset-toy-add-entities-cpu-2-bs-no-clip                     4   \n",
       "modelling-metadata-c4-dataset-toy-add-entities-cpu-1-bs-no-clip                     4   \n",
       "download_data                                                                       4   \n",
       "modelling-metadata-c4-dataset-gzip-data                                             3   \n",
       "joint-toy-4-test-gpt2-xl-mod-metadata                                               3   \n",
       "tr8-104B-data-study-data-no-basic-junk                                              3   \n",
       "all_datasets_bs2560_hard_neg                                                        3   \n",
       "modelling-metadata-website-desc-load-dataset                                        3   \n",
       "modelling-metadata-html-XX                                                          3   \n",
       "modelling-metadata-example-path                                                     3   \n",
       "modelling-metadata-website-desc-create-dataset                                      2   \n",
       "modelling-metadata-test-database-download                                           2   \n",
       "modelling-metadata-c4-push-to-hub                                                   2   \n",
       "convert_dataset_jsonl_dedup                                                         2   \n",
       "modelling-metadata-exp1-subexp2-load-dataset                                        2   \n",
       "modelling-metadata-exp1-subexp3-load-dataset                                        2   \n",
       "modelling-metadata-c4-dataset-toy-download-flair-model                              2   \n",
       "all_datasets                                                                        2   \n",
       "modelling-metadata-c4-dataset-toy-add-entities-cpu-1-bs-clip-5000-full              2   \n",
       "modelling-metadata-c4-dataset-toy-add-entities-cpu-1-bs-no-clip-full                2   \n",
       "modelling-metadata-html-exp1-subexp1-train                                          2   \n",
       "tr8-104B-data-study-data-junk-with-stopwords                                        1   \n",
       "tr8-104B-data-study-data-basic-junk-only                                            1   \n",
       "tr8-104B-data-study-data-with-only-slashes                                          1   \n",
       "modelling-metadata-website-desc-clean-train-25k                                     1   \n",
       "tr8-104B-data-study-data-basic-junk                                                 1   \n",
       "tr8-104B-data-study-TEMPLATE                                                        1   \n",
       "reduce_all_datasets                                                                 1   \n",
       "all_datasets_bs3072_hard_neg                                                        1   \n",
       "tr8-104B-data-study-data-basic-junk-only2                                           1   \n",
       "modelling-metadata-entity-metadata-example-create-dataset                           1   \n",
       "tr8-104B-data-study-data-basic-junk-and-low-stopwords                               1   \n",
       "tr8-104B-data-study-data-basic-junk-and-low-stopwords2                              1   \n",
       "modelling-metadata-entity-load-dataset                                              1   \n",
       "modelling-metadata-c4-import-dataset-retry                                          1   \n",
       "modelling-metadata-c4-import-dataset-more-time                                      1   \n",
       "modelling-metadata-c4-import-dataset                                                1   \n",
       "modelling-metadata-entity-example-train                                             1   \n",
       "modelling-metadata-website-desc-train                                               1   \n",
       "modelling-metadata-entity-beg-load-dataset                                          1   \n",
       "modelling-metadata-html-metadata-example-create-dataset                             1   \n",
       "modelling-metadata-c4-dataset_import-c4                                             1   \n",
       "modelling-metadata-html-metadata-exp1-subexp3-create-dataset                        1   \n",
       "modelling-metadata-html-exp1-subexp3-train                                          1   \n",
       "modelling-metadata-html-metadata-exp1-subexp2-transform-checkpoints                 1   \n",
       "modelling-metadata-html-metadata-exp1-subexp3-transform-checkpoints                 1   \n",
       "modelling-metadata-exp1-subexp1-load-dataset                                        1   \n",
       "Name: jobname, dtype: int64"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadf['jobname'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
